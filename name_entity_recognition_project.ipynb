{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "name entity recognition_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOf2gBMX9/NB7lzrErn6/bc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahra75koosha/zahra-koosha/blob/master/name_entity_recognition_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl1wy9nB6A60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 uninstall tensorflow\n",
        "!pip3 install tensorflow.gpu==2.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRYjydeE6JkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install hazm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTpWkuob6sd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcXjUx-J6zP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "83b6b1fa-e433-47b5-bf95-e1dac34c25db"
      },
      "source": [
        "%cd /content/drive/My Drive/\n",
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "\u001b[0m\u001b[01;34m'Colab Notebooks'\u001b[0m/   dev.txt   test.txt   train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Ol1t6I68iO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "45780a82-bd40-480e-f6ca-40c199e53493"
      },
      "source": [
        "import pandas as pd\n",
        "import sklearn \n",
        "import sys, os, re, codecs\n",
        "import gensim.models.keyedvectors as word2vec\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Embedding, Dropout, GlobalMaxPool1D\n",
        "from keras.layers import GRU, SimpleRNN\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from hazm import *"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvatXkyJ7Aap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = open(\"/content/drive/My Drive/train.txt\")\n",
        "dev_data= open(\"/content/drive/My Drive/dev.txt\")"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3T3rfhG7C52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "30e7356f-65fd-4357-b1d9-69bac1b71b60"
      },
      "source": [
        "print(train_data.read(100))"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "به O\n",
            "عنوان O\n",
            "مثال O\n",
            "وقتی O\n",
            "نشریات O\n",
            "مدافع O\n",
            "اصول O\n",
            "و O\n",
            "ارزشها O\n",
            "و O\n",
            "منادی O\n",
            "انقلاب O\n",
            "و O\n",
            "اسلام O\n",
            "در \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqBdxWmy7NxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert dataset to dataframe type\n",
        "\n",
        "list_columns = ['sentence','label']\n",
        "\n",
        "def read_data(dataset):\n",
        "    df= pd.DataFrame(columns=list_columns)\n",
        "    \n",
        "    file = open(dataset)\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for line in file:\n",
        "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
        "            if len(sentence) > 0:\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "            continue\n",
        "        splits = line.split(' ')        \n",
        "        sentence.append([splits[0], splits[-1]])\n",
        "\n",
        "    if len(sentence) > 0:\n",
        "        sentences.append(sentence)\n",
        "        sentence = []\n",
        "        \n",
        "    for sentence in sentences:\n",
        "      text=''\n",
        "      words=[]\n",
        "      values=[]\n",
        "      for item in sentence:\n",
        "        words.append(item[0])\n",
        "        values.append(item[1].replace('\\n',''))\n",
        "      _list=[]\n",
        "      _list.append(' '.join(words))\n",
        "      _list.append(' '.join(values))\n",
        "      df2 = pd.DataFrame([_list], columns=list_columns)\n",
        "      df=df.append(df2, ignore_index=True)\n",
        "    return df"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SYT0tcP7Up3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_set = read_data(\"/content/drive/My Drive/train.txt\")"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwhL-QV77Yfl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "2080eb69-1616-490b-b961-8c065f551231"
      },
      "source": [
        "train_data_set\n"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>به عنوان مثال وقتی نشریات مدافع اصول و ارزشها ...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>دکتر اصغری دبیر چهارمین همایش انجمن زمین‌شناسی...</td>\n",
              "      <td>O B-pers O B-event I-event I-event I-event I-e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>دکتر اکبر میرعرب در همایش بررسی و پیشگیری از ب...</td>\n",
              "      <td>O B-pers I-pers O B-event I-event I-event I-ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>اردبیل ـ استاندار اردبیل گفت : به مناسبت هفته ...</td>\n",
              "      <td>B-loc O O B-loc O O O O B-event I-event O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>حمید طاهایی افزود : برای اجرای این طرحها 0 میل...</td>\n",
              "      <td>B-pers I-pers O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10236</th>\n",
              "      <td>می‌خواهم بچه داشته باشم ولی نه در اینجا .</td>\n",
              "      <td>O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10237</th>\n",
              "      <td>می‌دانم با رفتنم همه را از دست خواهم داد ولی ب...</td>\n",
              "      <td>O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10238</th>\n",
              "      <td>حدود هفتاد و پنج نفر در یک اتاق کوچک جمع شده ب...</td>\n",
              "      <td>O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10239</th>\n",
              "      <td>داستان زندگی و مهاجرت آتی او به نمایش گذاشته شد .</td>\n",
              "      <td>O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10240</th>\n",
              "      <td>هنگامی که نمایش تمام شد و عروسکها روی صحنه روی...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10241 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence                                              label\n",
              "0      به عنوان مثال وقتی نشریات مدافع اصول و ارزشها ...  O O O O O O O O O O O O O O O O O O O O O O O ...\n",
              "1      دکتر اصغری دبیر چهارمین همایش انجمن زمین‌شناسی...  O B-pers O B-event I-event I-event I-event I-e...\n",
              "2      دکتر اکبر میرعرب در همایش بررسی و پیشگیری از ب...  O B-pers I-pers O B-event I-event I-event I-ev...\n",
              "3      اردبیل ـ استاندار اردبیل گفت : به مناسبت هفته ...  B-loc O O B-loc O O O O B-event I-event O O O ...\n",
              "4      حمید طاهایی افزود : برای اجرای این طرحها 0 میل...    B-pers I-pers O O O O O O O O O O O O O O O O O\n",
              "...                                                  ...                                                ...\n",
              "10236          می‌خواهم بچه داشته باشم ولی نه در اینجا .                                  O O O O O O O O O\n",
              "10237  می‌دانم با رفتنم همه را از دست خواهم داد ولی ب...                          O O O O O O O O O O O O O\n",
              "10238  حدود هفتاد و پنج نفر در یک اتاق کوچک جمع شده ب...                          O O O O O O O O O O O O O\n",
              "10239  داستان زندگی و مهاجرت آتی او به نمایش گذاشته شد .                              O O O O O O O O O O O\n",
              "10240  هنگامی که نمایش تمام شد و عروسکها روی صحنه روی...      O O O O O O O O O O O O O O O O O O O O O O O\n",
              "\n",
              "[10241 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iJymyJM7ej-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_data_set = read_data(\"/content/drive/My Drive/dev.txt\")"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnHMPbWW7jgm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "2670888b-bc84-491c-ceb6-06202a074b2e"
      },
      "source": [
        "dev_data_set"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>وي افزود : کمیته کشوری مبارزه با بیماری ایدز د...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>دکتر اکبر میرعرب در همایش بررسی و پیشگیری از ب...</td>\n",
              "      <td>O B-pers I-pers O B-event I-event I-event I-ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>حمید طاهایی افزود : برای اجرای این طرحها 0 میل...</td>\n",
              "      <td>B-pers I-pers O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>طاهایی گفت : 0 طرح عمرانی ، 0 طرح مدرسه‌سازی د...</td>\n",
              "      <td>B-pers O O O O O O O O O O O O O O O O O O O O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>تل‌مش تپه‌ای باستانی متعلق به هزاره چهارم پیش ...</td>\n",
              "      <td>B-loc O O O O O O O O O O O O O O O B-loc I-lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5115</th>\n",
              "      <td>اگر اینجا بمانم ، خفه خواهم شد .</td>\n",
              "      <td>O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5116</th>\n",
              "      <td>هر لحظه از زندگیم را تا هنگام مرگ می‌توانم ، پ...</td>\n",
              "      <td>O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5117</th>\n",
              "      <td>ویکا چند شب قبل از عزیمت به اسرائیل به اتفاق م...</td>\n",
              "      <td>B-pers O O O O O O B-loc O O O O O O O O O O O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5118</th>\n",
              "      <td>دوستان ویکا به جای عروسک صحبت می‌کردند .</td>\n",
              "      <td>O B-pers O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5119</th>\n",
              "      <td>هنگامی که نمایش تمام شد و عروسکها روی صحنه روی...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5120 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence                                              label\n",
              "0     وي افزود : کمیته کشوری مبارزه با بیماری ایدز د...  O O O O O O O O O O O O O O O O O O O O O O O ...\n",
              "1     دکتر اکبر میرعرب در همایش بررسی و پیشگیری از ب...  O B-pers I-pers O B-event I-event I-event I-ev...\n",
              "2     حمید طاهایی افزود : برای اجرای این طرحها 0 میل...    B-pers I-pers O O O O O O O O O O O O O O O O O\n",
              "3     طاهایی گفت : 0 طرح عمرانی ، 0 طرح مدرسه‌سازی د...  B-pers O O O O O O O O O O O O O O O O O O O O...\n",
              "4     تل‌مش تپه‌ای باستانی متعلق به هزاره چهارم پیش ...  B-loc O O O O O O O O O O O O O O O B-loc I-lo...\n",
              "...                                                 ...                                                ...\n",
              "5115                   اگر اینجا بمانم ، خفه خواهم شد .                                    O O O O O O O O\n",
              "5116  هر لحظه از زندگیم را تا هنگام مرگ می‌توانم ، پ...                          O O O O O O O O O O O O O\n",
              "5117  ویکا چند شب قبل از عزیمت به اسرائیل به اتفاق م...  B-pers O O O O O O B-loc O O O O O O O O O O O...\n",
              "5118           دوستان ویکا به جای عروسک صحبت می‌کردند .                               O B-pers O O O O O O\n",
              "5119  هنگامی که نمایش تمام شد و عروسکها روی صحنه روی...      O O O O O O O O O O O O O O O O O O O O O O O\n",
              "\n",
              "[5120 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21wPF7TU7odo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6bb3c29-de82-41d9-d7de-fc4d1feb99f6"
      },
      "source": [
        "type(dev_data_set)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AqKnb4W7rQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentence = train_data_set['sentence']\n",
        "train_label = train_data_set['label']"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDQFDgTU7v2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_sentence = dev_data_set['sentence']\n",
        "dev_labels = dev_data_set['label']"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt0Ezd9e7y_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "7d7167df-960f-47a8-b017-13630edf75ab"
      },
      "source": [
        "train_sentence[:10]"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    به عنوان مثال وقتی نشریات مدافع اصول و ارزشها ...\n",
              "1    دکتر اصغری دبیر چهارمین همایش انجمن زمین‌شناسی...\n",
              "2    دکتر اکبر میرعرب در همایش بررسی و پیشگیری از ب...\n",
              "3    اردبیل ـ استاندار اردبیل گفت : به مناسبت هفته ...\n",
              "4    حمید طاهایی افزود : برای اجرای این طرحها 0 میل...\n",
              "5    اصفهان ـ 0 تپه و محوطه باستانی دوره‌های تاریخی...\n",
              "6    پیشینه این محوطه‌های باستانی ، مربوط به پیش از...\n",
              "7    تل‌مش تپه‌ای باستانی متعلق به هزاره چهارم پیش ...\n",
              "8    محسن جاوری ، سرپرست هیأت باستان‌شناسی این مناط...\n",
              "9    میل سنگی دوره ساسانی با ارتفاع 0 سانتیمتر و غا...\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1gPvmFs74SN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "83f0bec8-3d70-42c2-d847-858552ed1f0e"
      },
      "source": [
        "train_label[:10]"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    O O O O O O O O O O O O O O O O O O O O O O O ...\n",
              "1    O B-pers O B-event I-event I-event I-event I-e...\n",
              "2    O B-pers I-pers O B-event I-event I-event I-ev...\n",
              "3    B-loc O O B-loc O O O O B-event I-event O O O ...\n",
              "4      B-pers I-pers O O O O O O O O O O O O O O O O O\n",
              "5    B-loc O O O O O O O O O O O O O O B-loc I-loc ...\n",
              "6                    O O O O O O O O O O O O O O O O O\n",
              "7    B-loc O O O O O O O O O O O O O O O B-loc I-lo...\n",
              "8    B-pers I-pers O O O O O O O O O O O O O O O O ...\n",
              "9    B-pro I-pro O O O O O O O O O O O O B-loc I-lo...\n",
              "Name: label, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Ef4iLTOS8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_to_one_hot(value):\n",
        "  list_classes = ['B-pers','I-pers', 'B-pro', 'I-pro','B-loc','I-loc','B-fac','I-fac','B-event','I-event','B-org','I-org','O']\n",
        "  if value == list_classes[0]:\n",
        "    return [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "  if value == list_classes[1]:\n",
        "    return [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "  if value == list_classes[2]:\n",
        "    return [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "  if value == list_classes[3]:\n",
        "    return [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "  if value == list_classes[4]:\n",
        "    return [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "  if value == list_classes[5]:\n",
        "    return [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "  if value == list_classes[6]:\n",
        "    return [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "  if value == list_classes[7]:\n",
        "    return [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
        "  if value == list_classes[8]:\n",
        "    return [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
        "  if value == list_classes[9]:\n",
        "    return [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
        "  if value == list_classes[10]:\n",
        "    return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "  if value == list_classes[11]:\n",
        "    return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
        "  if value == list_classes[12]:\n",
        "    return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDzgGjAt-XcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 250015\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_sentence))\n",
        "tokenized_train = tokenizer.texts_to_sequences(train_sentence)\n",
        "\n",
        "train_labels = [[label_to_one_hot(c) for c in ey.split(' ')] for ey in train_label]"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRWitOWnPI_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c89e13d7-c808-434e-b40e-2cc55dea218b"
      },
      "source": [
        "tokenized_train[4]"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2942, 8677, 65, 12, 234, 6, 1507, 10, 188, 1, 10, 125, 253, 535, 449, 21, 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL-VotGtPI6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "cc6f7b82-13f3-4452-c36f-286fdc65ebd3"
      },
      "source": [
        "train_labels[4]"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqiFNs80Peur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6ac59d9-cd85-442d-cf07-477622c3232b"
      },
      "source": [
        "# Find maximum length of training sentences\n",
        "max_length = max([len(s) for s in tokenized_train])\n",
        "max_length\n"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "238"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCk5R9A5PeaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad embeded training sequences\n",
        "x_train_padded = pad_sequences(tokenized_train, maxlen=max_length, padding='post')\n",
        "y_train_padded = pad_sequences(train_labels, maxlen=max_length, padding='post')"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwPTzbQCQtTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "550bdf65-83e9-4f2b-bf89-9342d7ab7734"
      },
      "source": [
        "x_train_padded[4]"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2942, 8677,   65,   12,  234,    6, 1507,   10,  188,    1,   10,\n",
              "        125,  253,  535,  449,   21,    9,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZNBZPKePeLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "3412b967-9081-4deb-aa81-1caf4ccb8ec4"
      },
      "source": [
        "y_train_padded[4]"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS8mKiaGRPK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vocabulary size\n",
        "vocab_size = len(tokenizer.word_index)"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMbvjAjDRFre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_blstm = Sequential()\n",
        "\n",
        "model_blstm.add(Embedding(vocab_size, 300, input_length=max_length))\n",
        "model_blstm.add(Bidirectional(LSTM(300, return_sequences=True, name='lstm_layer')))\n",
        "\n",
        "model_blstm.add(GlobalMaxPool1D())\n",
        "model_blstm.add(Dropout(0.25))\n",
        "model_blstm.add(Dense(300, activation=\"relu\"))\n",
        "model_blstm.add(Dropout(0.2))\n",
        "model_blstm.add(Dense(5, activation='softmax'))\n"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9UQojpJRFiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "3d4d9832-024f-4526-befe-0ae2b5180801"
      },
      "source": [
        "model_blstm.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=[\"categorical_accuracy\"])\n",
        "\n",
        "model_blstm.summary()\n",
        "batch_size_blstm = 64\n",
        "epochs_blstm = 12"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 238, 300)          5462400   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 238, 600)          1442400   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 600)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 600)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 300)               180300    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 1505      \n",
            "=================================================================\n",
            "Total params: 7,086,605\n",
            "Trainable params: 7,086,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzu2XLYxRmFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "51f53510-e3a6-4066-fc43-4885196a3a2e"
      },
      "source": [
        "hist_blstm = model_blstm.fit(x_train_padded, y_train_padded,\n",
        "                             batch_size=batch_size_blstm, epochs=epochs_blstm,\n",
        "                             shuffle=True)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-215-e874aeb1226d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist_blstm = model_blstm.fit(x_train_padded, y_train_padded,\n\u001b[1;32m      2\u001b[0m                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size_blstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_blstm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              shuffle=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2536\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2538\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    741\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    742\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                            'as the output.')\n",
            "\u001b[0;31mValueError\u001b[0m: A target array with shape (10241, 238, 13) was passed for an output of shape (None, 5) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTyff2XC9fa3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "af2063d8-b1cd-4e04-bedb-c849b2038061"
      },
      "source": [
        "'''import numpy as np\n",
        "# Convert dataframes to numpy arrays\n",
        "train_sentence = np.asarray(train_sentence)\n",
        "train_label = np.asarray(train_label)'''"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'import numpy as np\\n# Convert dataframes to numpy arrays\\ntrain_sentence = np.asarray(train_sentence)\\ntrain_label = np.asarray(train_label)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gHF_Gpw9BjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''import re\n",
        "normalizer = Normalizer()\n",
        "\n",
        "# turn a doc into clean tokens\n",
        "def clean_data(doc):\n",
        "    doc = normalizer.normalize(doc) # Normalize document using Hazm Normalizer\n",
        "    #tokenized = word_tokenize(doc)  # Tokenize text\n",
        "    \n",
        "\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "      token = re.sub(\"[،:.,;()/+]\", \" \", token) \n",
        "    \n",
        "      tokens.append(token)\n",
        "\n",
        "\n",
        "    return tokens'''"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwjOHNbB94Q5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "adcc5026-a692-4353-842e-915f234b0ebe"
      },
      "source": [
        "'''# Apply preprocessing step to training data\n",
        "words = np.empty_like(train_sentence)\n",
        "for index, document in enumerate(train_sentence):\n",
        "  words[index] = clean_data(document)'''"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-bfd403a1b22b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-175-ac5137b2c652>\u001b[0m in \u001b[0;36mclean_data\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# turn a doc into clean tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Normalize document using Hazm Normalizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#tokenized = word_tokenize(doc)  # Tokenize text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hazm/Normalizer.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharacter_refinement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affix_spacing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffix_spacing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hazm/Normalizer.py\u001b[0m in \u001b[0;36mcharacter_refinement\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    101\u001b[0m \t\t\"\"\"\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharacter_refinement_patterns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_io.TextIOWrapper' object has no attribute 'translate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB4d6CqZ_GY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q33tRW_0_Jaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHCQz7XOICuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x_mD_1J_MbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uju8XcrcICqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6UUUYGLENr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_6hp2N0EYKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiqjUALFEmV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJS-cvZbEqnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 215,
      "outputs": []
    }
  ]
}