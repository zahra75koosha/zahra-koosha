# -*- coding: utf-8 -*-
"""hoda_handwritten_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gbJkLfJcQzP-XfxHDETcMFkbv5kh2Vfo
"""

!pip3 uninstall tensorflow
!pip3 install tensorflow.gpu==2.0.0

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/hoda dataset
# %ls

# Commented out IPython magic to ensure Python compatibility.
from hoda_dataset_helper import read_hoda
from hoda_dataset_helper import __read_hoda_dataset
from hoda_dataset_helper import __read_hoda_cdb

import os
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
np.random.seed(2)

from tensorflow.keras.utils import to_categorical
import tensorflow as tf
from tensorflow.keras import Model 
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Dense, MaxPool2D, Dropout, Flatten

"""Load Dataset"""

# Reading train dataset 
X_train, Y_train = __read_hoda_dataset(dataset_path='./Train 60000.cdb',
                                images_height=32,
                                images_width=32,
                                one_hot=False ,
                                reshape=False)

# reading test dataset
X_test, Y_test = __read_hoda_dataset(dataset_path='./Test 20000.cdb',
                              images_height=32,
                              images_width=32,
                              one_hot=False,
                              reshape=False)

# Reading remain dataset
X_remain, Y_remain = __read_hoda_dataset('./RemainingSamples.cdb',
                                             images_height=32,
                                             images_width=32,
                                             one_hot=False,
                                             reshape=False)

# reading train image
train_images, train_labels = __read_hoda_cdb('./Train 60000.cdb')

# reading test image
test_images, test_labels = __read_hoda_cdb('./Test 20000.cdb')

# plot a data sample

fig = plt.figure(figsize=(15, 3))
plt.imshow(train_images[11])

#normalization
X_train =X_train / 255.0
X_test = X_test /255.0
X_remain= X_remain /255.0

# reshape the train and remain samples to 3 dimension
X_train= X_train.reshape(60000,32,32,1)
X_remain= X_remain.reshape(22352,32,32,1)
X_test= X_test.reshape(20000,32,32,1)

Y_train  =   to_categorical(Y_train, num_classes = 10)
Y_test   =   to_categorical(Y_test, num_classes = 10)
Y_remain =   to_categorical(Y_remain, num_classes = 10)

print(f'shape of X_train : {X_train.shape}')
print(f'shape of Y_train : {Y_train.shape}')

print(f'shape of X_test i: {X_test.shape}')
print(f'shape of Y_test  : {Y_test.shape}')

print(f'shape of X_reamin : {X_remain.shape}')
print(f'shape of Y_remain : {Y_remain.shape}')


# split training dataset to validation and train samples
random_seed=2
from sklearn.model_selection import train_test_split
X_train,X_val,Y_train,Y_val= train_test_split(X_train,Y_train,test_size=0.1, random_state=random_seed)

print(f'shape of X_val is : {X_val.shape}')
print(f'shape of Y_val is : {Y_val.shape}')



"""CNN model"""

model= Sequential()

model.add(Conv2D(32,(5,5), activation='relu', padding='same', input_shape=(32,32,1)))
model.add(Conv2D(32,(5,5), activation='relu', padding='same'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Conv2D(64,(3,3), activation='relu', padding='same'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Dropout(0.25))
model.add(Conv2D(32,(3,3), activation='relu', padding='same'))#

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(10, activation='softmax'))


model.summary()

model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
epochs = 40
batch_size = 32
result=model.fit(X_train, Y_train,epochs=epochs, batch_size=batch_size, validation_data=(X_val,Y_val), verbose=1)

# plot train and validation accuracy

plt.plot(result.history['accuracy'], color='b', label='training accuracy')
plt.plot(result.history['val_accuracy'], color='r', label='validation accuracy')
plt.title('Accuracy Of Model')
plt.ylabel(' Accuracy')
plt.xlabel('  Epoch')
plt.legend(['Train', 'Validation'], loc='lower right')
plt.show()

# plot train and validation accuracy

plt.plot(result.history['loss'], color='b', label='training loss')
plt.plot(result.history['val_loss'], color='r', label='validation loss')
plt.title('Loss Of Model')
plt.ylabel(' Loss')
plt.xlabel('  Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

model.evaluate(X_val, Y_val, verbose=1)
model.evaluate(X_test, Y_test, verbose=1)


import pandas as pd

results = model.predict(X_test)
results = np.argmax(results,axis = 1)
results = pd.Series(results)


results


submission = pd.concat([pd.Series(range(1,28001),name = "ImageId"),results],axis = 1)
submission.to_csv("cnn_hoda_dataset.csv",index=False)


model_2.summary()